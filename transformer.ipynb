{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3371fc719a040f3a23ae24dff92d57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6997, 'grad_norm': 4.187872886657715, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.05}\n",
      "{'loss': 0.7001, 'grad_norm': 4.38828706741333, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6995, 'grad_norm': 10.862085342407227, 'learning_rate': 3e-06, 'epoch': 0.15}\n",
      "{'loss': 0.6972, 'grad_norm': 4.894044876098633, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 0.6612, 'grad_norm': 5.634861469268799, 'learning_rate': 5e-06, 'epoch': 0.25}\n",
      "{'loss': 0.6483, 'grad_norm': 5.30477237701416, 'learning_rate': 6e-06, 'epoch': 0.3}\n",
      "{'loss': 0.6328, 'grad_norm': 5.983886241912842, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.35}\n",
      "{'loss': 0.5545, 'grad_norm': 3.969754695892334, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 0.5299, 'grad_norm': 6.153872966766357, 'learning_rate': 9e-06, 'epoch': 0.45}\n",
      "{'loss': 0.4838, 'grad_norm': 4.7420654296875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4124, 'grad_norm': 7.5845513343811035, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3789, 'grad_norm': 7.741362571716309, 'learning_rate': 1.2e-05, 'epoch': 0.6}\n",
      "{'loss': 0.237, 'grad_norm': 8.96961784362793, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.65}\n",
      "{'loss': 0.2538, 'grad_norm': 8.609063148498535, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2993, 'grad_norm': 9.24463939666748, 'learning_rate': 1.5e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2816, 'grad_norm': 10.700004577636719, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1615, 'grad_norm': 10.503593444824219, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.85}\n",
      "{'loss': 0.1335, 'grad_norm': 20.047121047973633, 'learning_rate': 1.8e-05, 'epoch': 0.9}\n",
      "{'loss': 0.1227, 'grad_norm': 26.16728401184082, 'learning_rate': 1.9e-05, 'epoch': 0.95}\n",
      "{'loss': 0.2663, 'grad_norm': 0.2966485023498535, 'learning_rate': 2e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5023104fd7a4a928ca7fbbbacf9f0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15072660148143768, 'eval_runtime': 123.8383, 'eval_samples_per_second': 3.23, 'eval_steps_per_second': 0.202, 'epoch': 1.0}\n",
      "{'loss': 0.1237, 'grad_norm': 1.5623177289962769, 'learning_rate': 2.1e-05, 'epoch': 1.05}\n",
      "{'loss': 0.1508, 'grad_norm': 0.23821298778057098, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2532, 'grad_norm': 23.612327575683594, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.15}\n",
      "{'loss': 0.1199, 'grad_norm': 21.220016479492188, 'learning_rate': 2.4e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2061, 'grad_norm': 24.81610679626465, 'learning_rate': 2.5e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2456, 'grad_norm': 6.029068946838379, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0245, 'grad_norm': 0.10445565730333328, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0121, 'grad_norm': 0.07144901156425476, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.4}\n",
      "{'loss': 0.267, 'grad_norm': 0.16397790610790253, 'learning_rate': 2.9e-05, 'epoch': 1.45}\n",
      "{'loss': 0.1511, 'grad_norm': 67.9458999633789, 'learning_rate': 3e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0915, 'grad_norm': 24.054059982299805, 'learning_rate': 3.1e-05, 'epoch': 1.55}\n",
      "{'loss': 0.2617, 'grad_norm': 29.562772750854492, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2255, 'grad_norm': 0.1012168601155281, 'learning_rate': 3.3e-05, 'epoch': 1.65}\n",
      "{'loss': 0.028, 'grad_norm': 9.47092056274414, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0444, 'grad_norm': 0.042355768382549286, 'learning_rate': 3.5e-05, 'epoch': 1.75}\n",
      "{'loss': 0.2616, 'grad_norm': 0.11225629597902298, 'learning_rate': 3.6e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0372, 'grad_norm': 43.93442916870117, 'learning_rate': 3.7e-05, 'epoch': 1.85}\n",
      "{'loss': 0.0614, 'grad_norm': 0.703624963760376, 'learning_rate': 3.8e-05, 'epoch': 1.9}\n",
      "{'loss': 0.1369, 'grad_norm': 4.965708255767822, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.95}\n",
      "{'loss': 0.0732, 'grad_norm': 0.1840285360813141, 'learning_rate': 4e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb858b57839405196ef833548d81526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09576446563005447, 'eval_runtime': 126.6603, 'eval_samples_per_second': 3.158, 'eval_steps_per_second': 0.197, 'epoch': 2.0}\n",
      "{'loss': 0.002, 'grad_norm': 0.0415000356733799, 'learning_rate': 4.1e-05, 'epoch': 2.05}\n",
      "{'loss': 0.0068, 'grad_norm': 0.03763734549283981, 'learning_rate': 4.2e-05, 'epoch': 2.1}\n",
      "{'loss': 0.1577, 'grad_norm': 0.015218440443277359, 'learning_rate': 4.3e-05, 'epoch': 2.15}\n",
      "{'loss': 0.1268, 'grad_norm': 76.41204071044922, 'learning_rate': 4.4000000000000006e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0068, 'grad_norm': 10.498577117919922, 'learning_rate': 4.5e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0789, 'grad_norm': 44.01468276977539, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0004, 'grad_norm': 0.009821274317800999, 'learning_rate': 4.7e-05, 'epoch': 2.35}\n",
      "{'loss': 0.0541, 'grad_norm': 0.007755990605801344, 'learning_rate': 4.8e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0937, 'grad_norm': 0.036877699196338654, 'learning_rate': 4.9e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0107, 'grad_norm': 0.02014358900487423, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
      "{'loss': 0.1217, 'grad_norm': 0.08174251765012741, 'learning_rate': 4.5e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0789, 'grad_norm': 0.008473450317978859, 'learning_rate': 4e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1581, 'grad_norm': 0.025373252108693123, 'learning_rate': 3.5e-05, 'epoch': 2.65}\n",
      "{'loss': 0.099, 'grad_norm': 67.1280746459961, 'learning_rate': 3e-05, 'epoch': 2.7}\n",
      "{'loss': 0.1611, 'grad_norm': 0.4877029359340668, 'learning_rate': 2.5e-05, 'epoch': 2.75}\n",
      "{'loss': 0.0009, 'grad_norm': 0.04979431629180908, 'learning_rate': 2e-05, 'epoch': 2.8}\n",
      "{'loss': 0.1227, 'grad_norm': 0.020233428105711937, 'learning_rate': 1.5e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0864, 'grad_norm': 0.013966741040349007, 'learning_rate': 1e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0007, 'grad_norm': 0.01767805963754654, 'learning_rate': 5e-06, 'epoch': 2.95}\n",
      "{'loss': 0.0665, 'grad_norm': 0.11515720188617706, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a6b325dd1544458cc7294f9dcdf764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1434956192970276, 'eval_runtime': 126.3702, 'eval_samples_per_second': 3.165, 'eval_steps_per_second': 0.198, 'epoch': 3.0}\n",
      "{'train_runtime': 4780.7547, 'train_samples_per_second': 1.004, 'train_steps_per_second': 0.126, 'train_loss': 0.2177262275161532, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e01fc07ecf24c448f837f972ae32302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       198\n",
      "           1       0.97      0.97      0.97       202\n",
      "\n",
      "    accuracy                           0.97       400\n",
      "   macro avg       0.97      0.97      0.97       400\n",
      "weighted avg       0.97      0.97      0.97       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain why this article might be classified as fake:\n",
      "\n",
      "The following is a list of the most common fake news stories that have been published by the media in the last year.\n",
      "\n",
      "Fake news stories that have been published by the media in\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('train.csv') \n",
    "df = df.dropna(subset=['text', 'label'])  # Ensure no NaN values in text or label columns\n",
    "\n",
    "df_sampled = df.sample(n=2000, random_state=42)  # Adjust n as needed\n",
    "texts = df_sampled['text'].tolist()\n",
    "labels = df_sampled['label'].tolist()\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Create a custom Dataset class\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              # Reduced number of epochs for quicker training\n",
    "    per_device_train_batch_size=8,   # Experiment with larger batch sizes as memory allows\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",      # Evaluate every epoch\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Step 1: Evaluate the model on the validation dataset\n",
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Step 2: Generate confusion matrix and classification report\n",
    "cm = confusion_matrix(labels, predicted_labels)\n",
    "report = classification_report(labels, predicted_labels)\n",
    "\n",
    "# Step 3: Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Print classification report\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Optional: Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./models/fake_news_bert\")\n",
    "tokenizer.save_pretrained(\"./models/fake_news_bert\")\n",
    "\n",
    "# Note: GPT integration for future implementation\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load GPT-2 model and tokenizer (optional)\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "def generate_text(prompt):\n",
    "    inputs = gpt_tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = gpt_model.generate(inputs, max_length=50, num_return_sequences=1)\n",
    "    return gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generate_text(\"Explain why this article might be classified as fake:\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\configuration_utils.py:623: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `70` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_13924\\4166090526.py\", line 34, in predict_news\n",
      "    gpt_output = gpt_model.generate(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1906, in generate\n",
      "    self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1228, in _validate_generated_length\n",
      "    raise ValueError(\n",
      "ValueError: Input length of input_ids is 237, but `max_length` is set to 160. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_13924\\4166090526.py\", line 34, in predict_news\n",
      "    gpt_output = gpt_model.generate(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1906, in generate\n",
      "    self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1228, in _validate_generated_length\n",
      "    raise ValueError(\n",
      "ValueError: Input length of input_ids is 167, but `max_length` is set to 160. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_13924\\4166090526.py\", line 34, in predict_news\n",
      "    gpt_output = gpt_model.generate(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1906, in generate\n",
      "    self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1228, in _validate_generated_length\n",
      "    raise ValueError(\n",
      "ValueError: Input length of input_ids is 2434, but `max_length` is set to 160. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_13924\\4166090526.py\", line 34, in predict_news\n",
      "    gpt_output = gpt_model.generate(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1906, in generate\n",
      "    self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1228, in _validate_generated_length\n",
      "    raise ValueError(\n",
      "ValueError: Input length of input_ids is 350, but `max_length` is set to 160. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_13924\\4166090526.py\", line 34, in predict_news\n",
      "    gpt_output = gpt_model.generate(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1906, in generate\n",
      "    self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1228, in _validate_generated_length\n",
      "    raise ValueError(\n",
      "ValueError: Input length of input_ids is 172, but `max_length` is set to 160. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_13924\\4166090526.py\", line 34, in predict_news\n",
      "    gpt_output = gpt_model.generate(\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1906, in generate\n",
      "    self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
      "  File \"C:\\Users\\chara\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py\", line 1228, in _validate_generated_length\n",
      "    raise ValueError(\n",
      "ValueError: Input length of input_ids is 172, but `max_length` is set to 160. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the fine-tuned BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"./models/fake_news_bert\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./models/fake_news_bert\")\n",
    "\n",
    "# Load GPT-2 model and tokenizer\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Function to predict if the news is real or fake\n",
    "def predict_news(article_text):\n",
    "    # Tokenization for BERT\n",
    "    inputs = tokenizer(article_text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    \n",
    "    # Model prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Convert label to human-readable form\n",
    "    prediction = \"Real\" if predicted_label == 1 else \"Fake\"\n",
    "\n",
    "    # Generate explanation using GPT-2\n",
    "    explanation_prompt = (\n",
    "        f\"The article below has been classified as {prediction.lower()}. \"\n",
    "        f\"Please provide a detailed and coherent explanation for this classification:\\n\\n\"\n",
    "        f\"Article: {article_text}\\n\\nExplanation:\"\n",
    "    )\n",
    "    gpt_input = gpt_tokenizer.encode(explanation_prompt, return_tensors='pt')\n",
    "    gpt_output = gpt_model.generate(\n",
    "        gpt_input, \n",
    "        max_length=160, \n",
    "        temperature=0.7,  # Adjust creativity\n",
    "        top_k=70,         # Limit the sampling space\n",
    "        top_p=0.9         # Nucleus sampling\n",
    "    )\n",
    "    explanation = gpt_tokenizer.decode(gpt_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove repetitive sentences\n",
    "    explanation_sentences = explanation.split('. ')\n",
    "    explanation = '. '.join(dict.fromkeys(explanation_sentences))\n",
    "\n",
    "    return prediction, explanation\n",
    "\n",
    "# Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_news,\n",
    "    inputs=gr.Textbox(lines=5, label=\"Enter News Article Text\"),\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=2, label=\"Prediction\"),\n",
    "        gr.Textbox(label=\"Explanation from GPT\")\n",
    "    ],\n",
    "    title=\"Fake News Detection\",\n",
    "    description=\"Enter a news article text, and the model will classify it as Real or Fake. Additionally, GPT will provide an explanation for the classification.\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
